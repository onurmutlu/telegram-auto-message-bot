"""
# ============================================================================ #
# Dosya: run_tests.py
# Yol: /Users/siyahkare/code/telegram-bot/tests/run_tests.py
# Ä°ÅŸlev: Telegram bot test ortamÄ± yÃ¶neticisi
#
# Build: 2025-04-01
# Versiyon: v3.4.0
# ============================================================================ #
#
# Bu modÃ¼l, Telegram bot uygulamasÄ±nÄ±n test ortamÄ±nÄ± yÃ¶netir ve test sÃ¼recini otomatikleÅŸtirir:
# - Test senaryolarÄ±nÄ± yÃ¼rÃ¼tme ve sonuÃ§larÄ± analiz etme
# - AyrÄ±ntÄ±lÄ± raporlama ve loglama imkanÄ±
# - Renkli terminal Ã§Ä±ktÄ±larÄ± ile test durumlarÄ±nÄ± gÃ¶rselleÅŸtirme
# - Test zaman aÅŸÄ±mÄ± ve hata yÃ¶netimi 
# - Test istatistiklerini yapÄ±landÄ±rÄ±lmÄ±ÅŸ bir ÅŸekilde sunma
#
# ============================================================================ #
"""
import os
import sys
import time
import pytest
import signal
import logging
import argparse
import subprocess
import re
import io
from datetime import datetime
from pathlib import Path
from unittest.mock import patch

# Colorama kÃ¼tÃ¼phanesini import et - terminal renkli Ã§Ä±ktÄ±lar iÃ§in
from colorama import init, Fore, Back, Style

# Colorama'yÄ± baÅŸlat (Windows'ta ANSI kodlarÄ±nÄ± Ã§alÄ±ÅŸtÄ±rabilmek iÃ§in)
init(autoreset=True)

# Log dizini oluÅŸtur
logs_dir = Path(__file__).parent.parent / "logs"
logs_dir.mkdir(exist_ok=True)

# Zaman damgalÄ± log dosya adÄ± oluÅŸtur
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
log_file = logs_dir / f"test_run_{timestamp}.log"
results_file = logs_dir / f"test_results_{timestamp}.log"

# Renkli formatlayÄ±cÄ± sÄ±nÄ±fÄ±
class ColoredFormatter(logging.Formatter):
    """
    Renkli log formatlarÄ± saÄŸlar.
    
    Bu sÄ±nÄ±f, farklÄ± log seviyelerine gÃ¶re Ã¶zelleÅŸtirilmiÅŸ renkli 
    formatlar oluÅŸturur ve terminal Ã§Ä±ktÄ±sÄ±nÄ± daha okunabilir hale getirir.
    """
    
    FORMATS = {
        logging.DEBUG: Fore.CYAN + "%(asctime)s - %(name)s - " + Fore.BLUE + "%(levelname)s" + Fore.RESET + " - %(message)s",
        logging.INFO: Fore.GREEN + "%(asctime)s - %(name)s - " + Fore.GREEN + "%(levelname)s" + Fore.RESET + " - %(message)s",
        logging.WARNING: Fore.YELLOW + "%(asctime)s - %(name)s - " + Fore.YELLOW + "%(levelname)s" + Fore.RESET + " - %(message)s",
        logging.ERROR: Fore.RED + "%(asctime)s - %(name)s - " + Fore.RED + "%(levelname)s" + Fore.RESET + " - %(message)s",
        logging.CRITICAL: Fore.WHITE + Back.RED + "%(asctime)s - %(name)s - " + "%(levelname)s" + Fore.RESET + Back.RESET + " - %(message)s"
    }
    
    def format(self, record):
        """
        Belirtilen log kaydÄ±nÄ± formatlar.
        
        Args:
            record: Formatlanacak log kaydÄ±
            
        Returns:
            str: FormatlanmÄ±ÅŸ log kaydÄ±
        """
        log_fmt = self.FORMATS.get(record.levelno)
        formatter = logging.Formatter(log_fmt)
        return formatter.format(record)

# GÃ¼venli loglama iÃ§in Ã¶zel bir sÄ±nÄ±f oluÅŸturalÄ±m
class SafeLogger(logging.Logger):
    """
    Handler'larÄ± gÃ¼venli bir ÅŸekilde kullanan logger sÄ±nÄ±fÄ±.
    
    Bu sÄ±nÄ±f, logger handler'larÄ±nÄ±n dÃ¼zgÃ¼n ÅŸekilde kapatÄ±lmasÄ±nÄ± saÄŸlayarak
    kaynak sÄ±zÄ±ntÄ±larÄ±nÄ± ve hatalarÄ± Ã¶nler. Ã–zellikle test ortamÄ± gibi
    kaynak yÃ¶netiminin kritik olduÄŸu durumlarda faydalÄ±dÄ±r.
    """
    
    def __init__(self, name, level=logging.NOTSET):
        """
        SafeLogger sÄ±nÄ±fÄ±nÄ±n baÅŸlatÄ±cÄ± metodu.
        
        Args:
            name (str): Logger adÄ±
            level (int): BaÅŸlangÄ±Ã§ log seviyesi
        """
        super().__init__(name, level)
        self._handlers_closed = False
    
    def close_handlers(self):
        """
        TÃ¼m handler'larÄ± gÃ¼venli bir ÅŸekilde kapatÄ±r.
        
        Bu metot, uygulama sonlandÄ±ÄŸÄ±nda veya hata durumunda
        tÃ¼m handler'larÄ±n dÃ¼zgÃ¼n ÅŸekilde kapatÄ±lmasÄ±nÄ± saÄŸlar.
        """
        if not self._handlers_closed:
            for handler in self.handlers:
                try:
                    handler.close()
                except Exception:
                    pass
            self._handlers_closed = True
    
    def _log(self, level, msg, args, **kwargs):
        """
        Handler'lar kapatÄ±ldÄ±ktan sonra log yazmayÄ± engeller.
        
        Args:
            level (int): Log seviyesi
            msg (str): Log mesajÄ±
            args (tuple): Format argÃ¼manlarÄ±
            **kwargs: Ek anahtar kelime argÃ¼manlarÄ±
        """
        if not self._handlers_closed:
            super()._log(level, msg, args, **kwargs)

# Logger yapÄ±landÄ±rmasÄ± iÃ§in Ã¶zel sÄ±nÄ±fÄ± kaydedelim
logging.setLoggerClass(SafeLogger)

# Logger oluÅŸtur
logger = logging.getLogger("test_runner")
logger.setLevel(logging.DEBUG)

# Ã–nceki handler'larÄ± temizle
for handler in logger.handlers[:]:
    logger.removeHandler(handler)

# Dosya handler - renkler olmadan normal format
file_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
file_handler = logging.FileHandler(log_file, encoding="utf-8")
file_handler.setFormatter(file_format)
file_handler.setLevel(logging.DEBUG)
logger.addHandler(file_handler)

# Console handler - renkli format
console_handler = logging.StreamHandler(sys.stdout)
console_handler.setFormatter(ColoredFormatter())
console_handler.setLevel(logging.INFO)
logger.addHandler(console_handler)

# Timeout sÃ¼resi - saniye cinsinden
DEFAULT_TIMEOUT = 30  # 30 saniye

# ASCII sanat baÅŸlÄ±ÄŸÄ±
ASCII_BANNER = fr"""
{Fore.CYAN}{Style.BRIGHT}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                              â•‘
â•‘  {Fore.YELLOW}â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—{Fore.CYAN}  â•‘
â•‘  {Fore.YELLOW}â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â• â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘{Fore.CYAN}  â•‘
â•‘  {Fore.YELLOW}   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘{Fore.CYAN}  â•‘
â•‘  {Fore.YELLOW}   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘{Fore.CYAN}  â•‘
â•‘  {Fore.YELLOW}   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘{Fore.CYAN}  â•‘
â•‘  {Fore.YELLOW}   â•šâ•â•   â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•     â•šâ•â•{Fore.CYAN}  â•‘
â•‘                                                              â•‘
â•‘             {Fore.MAGENTA}AUTO MESSAGE BOT v3.4.0 - TEST SUITE{Fore.CYAN}             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Style.RESET_ALL}
"""

def extract_test_results(output):
    """
    Pytest Ã§Ä±ktÄ±sÄ±ndan test sonuÃ§larÄ±nÄ± Ã§Ä±karÄ±r.
    
    Pytest Ã§Ä±ktÄ± metnini analiz ederek, Ã§alÄ±ÅŸtÄ±rÄ±lan testlerin
    istatistiksel bilgilerini Ã§Ä±karÄ±r.
    
    Args:
        output (str): pytest Ã§Ä±ktÄ±sÄ±
        
    Returns:
        dict: AyrÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ test istatistikleri
            {
                'total': Toplam test sayÄ±sÄ±,
                'passed': BaÅŸarÄ±lÄ± test sayÄ±sÄ±,
                'failed': BaÅŸarÄ±sÄ±z test sayÄ±sÄ±,
                'skipped': Atlanan test sayÄ±sÄ±,
                'errors': Hata sayÄ±sÄ±,
                'xfailed': Beklenen baÅŸarÄ±sÄ±zlÄ±k sayÄ±sÄ±,
                'xpassed': Beklenmeyen baÅŸarÄ± sayÄ±sÄ±,
                'warnings': UyarÄ± sayÄ±sÄ±
            }
    """
    stats = {
        'total': 0,
        'passed': 0, 
        'failed': 0, 
        'skipped': 0, 
        'errors': 0,
        'xfailed': 0,
        'xpassed': 0,
        'warnings': 0
    }
    
    # Toplam test sayÄ±sÄ±nÄ± al
    collected_match = re.search(r'collected (\d+) items', output)
    if collected_match:
        stats['total'] = int(collected_match.group(1))
    
    # SonuÃ§ detayÄ±nÄ± al - son satÄ±rdan bilgileri Ã§ek
    summary_lines = [line for line in output.split('\n') if re.search(r'\d+ passed', line) or re.search(r'\d+ failed', line)]
    if summary_lines:
        last_summary = summary_lines[-1]
        
        # Her kategori iÃ§in kontrol et
        passed_match = re.search(r'(\d+) passed', last_summary)
        if passed_match:
            stats['passed'] = int(passed_match.group(1))
        
        failed_match = re.search(r'(\d+) failed', last_summary)
        if failed_match:
            stats['failed'] = int(failed_match.group(1))
        
        skipped_match = re.search(r'(\d+) skipped', last_summary)
        if skipped_match:
            stats['skipped'] = int(skipped_match.group(1))
        
        errors_match = re.search(r'(\d+) errors', last_summary)
        if errors_match:
            stats['errors'] = int(errors_match.group(1))
            
        xfailed_match = re.search(r'(\d+) xfailed', last_summary)
        if xfailed_match:
            stats['xfailed'] = int(xfailed_match.group(1))
            
        xpassed_match = re.search(r'(\d+) xpassed', last_summary)
        if xpassed_match:
            stats['xpassed'] = int(xpassed_match.group(1))
            
        warnings_match = re.search(r'(\d+) warnings', last_summary)
        if warnings_match:
            stats['warnings'] = int(warnings_match.group(1))
    
    # Warnings sayÄ±sÄ± iÃ§in Ã¶zel kontrol - warnings summary bÃ¶lÃ¼mÃ¼nden
    if stats['warnings'] == 0:
        warnings_section = re.search(r'(\d+) warnings', output)
        if warnings_section:
            stats['warnings'] = int(warnings_section.group(1))
    
    return stats

def handle_timeout(signum, frame):
    """
    Timeout iÅŸleyici fonksiyonu.
    
    SIGALRM sinyali alÄ±ndÄ±ÄŸÄ±nda Ã§aÄŸrÄ±lÄ±r ve test sÃ¼recini sonlandÄ±rÄ±r.
    
    Args:
        signum (int): Sinyal numarasÄ±
        frame: Mevcut yÄ±ÄŸÄ±n Ã§erÃ§evesi
    """
    print(f"{Fore.RED}{Style.BRIGHT}âš ï¸  TIMEOUT: Test Ã§alÄ±ÅŸmasÄ± zaman aÅŸÄ±mÄ±na uÄŸradÄ±!{Style.RESET_ALL}")
    sys.exit(1)

def print_test_summary(stats, elapsed):
    """
    Test sonuÃ§larÄ±nÄ± Ã¶zetler ve yazdÄ±rÄ±r.
    
    Test koÅŸumu tamamlandÄ±ktan sonra istatistikleri renkli
    ve formatlanmÄ±ÅŸ bir ÅŸekilde konsola yazdÄ±rÄ±r.
    
    Args:
        stats (dict): Test istatistikleri
        elapsed (float): Test koÅŸumunun geÃ§en sÃ¼resi (saniye)
    """
    print(f"\n{Fore.CYAN}{Style.BRIGHT}ğŸ“Š Test Ã–zeti:{Style.RESET_ALL}")
    print(f"{Fore.BLUE}{'â”€' * 70}{Style.RESET_ALL}")
    
    # SonuÃ§ yorumu - BAÅARILI kriterlerini dÃ¼zelt: uyarÄ±lar, testin baÅŸarÄ±sÄ±nÄ± etkilemez
    if stats['failed'] > 0 or stats['errors'] > 0:
        result_str = f"{Fore.RED}{Style.BRIGHT}BAÅARISIZâŒ{Style.RESET_ALL}"
    elif stats['passed'] == 0 and stats['total'] == 0:
        result_str = f"{Fore.YELLOW}{Style.BRIGHT}TEST YOKâš ï¸{Style.RESET_ALL}"
    elif stats['passed'] > 0 and stats['passed'] == stats['total']:
        # TÃ¼m testler geÃ§ti, uyarÄ±lar olabilir ama bu testlerin baÅŸarÄ±lÄ± olmasÄ±nÄ± engellemez
        result_str = f"{Fore.GREEN}{Style.BRIGHT}BAÅARILIâœ…{Style.RESET_ALL}"
    elif stats['passed'] > 0 and stats['passed'] < stats['total']:
        # BazÄ± testler geÃ§ti, bazÄ±larÄ± atlandÄ± veya beklenen hata
        result_str = f"{Fore.YELLOW}{Style.BRIGHT}KISMÄ°âœ“âš ï¸{Style.RESET_ALL}"
    else:
        result_str = f"{Fore.YELLOW}{Style.BRIGHT}DURUMU BÄ°LÄ°NMÄ°YORâ“{Style.RESET_ALL}"
    
    # SÃ¼re deÄŸerlendirme
    if elapsed < 1.0:
        duration_str = f"{Fore.GREEN}Ã‡OK HIZLI ({elapsed:.2f}s)ğŸš€{Fore.RESET}"
    elif elapsed < 5.0:
        duration_str = f"{Fore.GREEN}HIZLI ({elapsed:.2f}s)âš¡{Fore.RESET}"
    elif elapsed < 15.0:
        duration_str = f"{Fore.YELLOW}NORMAL ({elapsed:.2f}s)â±ï¸{Fore.RESET}"
    else:
        duration_str = f"{Fore.RED}YAVAÅ ({elapsed:.2f}s)ğŸ¢{Fore.RESET}"
    
    # Test sayÄ±larÄ±nÄ± gÃ¶ster
    print(f"  {Fore.YELLOW}Genel Durum:{Fore.RESET} {result_str}")
    print(f"  {Fore.YELLOW}Toplam Test:{Fore.RESET} {stats['total']}")
    
    if stats['passed'] > 0:
        print(f"  {Fore.YELLOW}BaÅŸarÄ±lÄ±:{Fore.RESET} {Fore.GREEN}{stats['passed']}{Fore.RESET}")
    
    if stats['failed'] > 0:
        print(f"  {Fore.YELLOW}BaÅŸarÄ±sÄ±z:{Fore.RESET} {Fore.RED}{stats['failed']}{Fore.RESET}")
    
    if stats['errors'] > 0:
        print(f"  {Fore.YELLOW}Hatalar:{Fore.RESET} {Fore.RED}{stats['errors']}{Fore.RESET}")
    
    if stats['skipped'] > 0:
        print(f"  {Fore.YELLOW}Atlanan:{Fore.RESET} {Fore.YELLOW}{stats['skipped']}{Fore.RESET}")
    
    if stats['warnings'] > 0:
        print(f"  {Fore.YELLOW}UyarÄ±lar:{Fore.RESET} {Fore.YELLOW}{stats['warnings']}{Fore.RESET} (testlerin baÅŸarÄ±sÄ±nÄ± etkilemez)")
    
    if stats['xfailed'] > 0 or stats['xpassed'] > 0:
        print(f"  {Fore.YELLOW}Beklenen Hatalar:{Fore.RESET} {stats['xfailed']} | {Fore.YELLOW}Beklenmeyen GeÃ§iÅŸler:{Fore.RESET} {stats['xpassed']}")
    
    print(f"  {Fore.YELLOW}SÃ¼re:{Fore.RESET} {duration_str}")
    
    # Ã‡alÄ±ÅŸtÄ±rÄ±cÄ± bilgileri
    print(f"  {Fore.YELLOW}Test Ã‡alÄ±ÅŸtÄ±rÄ±cÄ±:{Fore.RESET} pytest-{pytest.__version__}")
    print(f"  {Fore.YELLOW}Python SÃ¼rÃ¼mÃ¼:{Fore.RESET} {sys.version.split()[0]}")
    print(f"  {Fore.YELLOW}Platform:{Fore.RESET} {sys.platform}")
    print(f"  {Fore.YELLOW}Tarih/Saat:{Fore.RESET} {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{Fore.BLUE}{'â”€' * 70}{Style.RESET_ALL}")
    
    # SonuÃ§ dosyasÄ±na da kaydet
    try:
        with open(results_file, 'w', encoding='utf-8') as f:
            f.write(f"Test Ã–zeti - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"{'â”€' * 70}\n")
            f.write(f"Genel Durum: {result_str.replace(Fore.RED, '').replace(Fore.GREEN, '').replace(Fore.YELLOW, '').replace(Style.BRIGHT, '').replace(Style.RESET_ALL, '')}\n")
            f.write(f"Toplam Test: {stats['total']}\n")
            f.write(f"BaÅŸarÄ±lÄ±: {stats['passed']}\n")
            f.write(f"BaÅŸarÄ±sÄ±z: {stats['failed']}\n")
            f.write(f"Hatalar: {stats['errors']}\n")
            f.write(f"Atlanan: {stats['skipped']}\n")
            f.write(f"UyarÄ±lar: {stats['warnings']}\n")
            f.write(f"Beklenen Hatalar: {stats['xfailed']}\n")
            f.write(f"Beklenmeyen GeÃ§iÅŸler: {stats['xpassed']}\n")
            f.write(f"SÃ¼re: {elapsed:.2f}s\n")
            f.write(f"{'â”€' * 70}\n")
    except Exception as e:
        logger.error(f"SonuÃ§ dosyasÄ± yazÄ±lÄ±rken hata: {e}")

def run_tests(verbose=False, failfast=False, test=None, timeout=DEFAULT_TIMEOUT, fix_warnings=False):
    """
    Testleri Ã§alÄ±ÅŸtÄ±rÄ±r ve sonuÃ§larÄ± deÄŸerlendirir.
    
    Bu fonksiyon, argÃ¼manlarla belirtilen testleri Ã§alÄ±ÅŸtÄ±rÄ±r,
    Ã§Ä±ktÄ±larÄ± kaydeder ve sonuÃ§larÄ± deÄŸerlendirir.
    
    Args:
        verbose (bool): AyrÄ±ntÄ±lÄ± Ã§Ä±ktÄ± gÃ¶stermek iÃ§in True
        failfast (bool): Ä°lk hatada testi durdurmak iÃ§in True
        test (str): Belirli bir test dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rmak iÃ§in dosya adÄ±
        timeout (int): Test zaman aÅŸÄ±mÄ± sÃ¼resi (saniye)
        fix_warnings (bool): UyarÄ±larÄ± gizlemek iÃ§in True
    
    Returns:
        tuple: (Ã§Ä±kÄ±ÅŸ_kodu, test_istatistikleri)
            Ã§Ä±kÄ±ÅŸ_kodu (int): 0 baÅŸarÄ±lÄ±, diÄŸerleri hata
            test_istatistikleri (dict): Test istatistikleri sÃ¶zlÃ¼ÄŸÃ¼
    """
    # Banner'Ä± yazdÄ±r
    print(ASCII_BANNER)
    
    # Log bilgilerini yazdÄ±r
    logger.info(f"{Fore.BLUE}ğŸ“Š {Style.BRIGHT}Test oturumu baÅŸlatÄ±ldÄ±{Style.RESET_ALL} â€¢ {Fore.CYAN}{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"{Fore.BLUE}ğŸ“ {Style.BRIGHT}Log dosyasÄ±:{Style.RESET_ALL} {log_file}")
    
    # Test parametrelerini yazdÄ±r
    test_params = []
    if verbose:
        test_params.append(f"{Fore.YELLOW}ayrÄ±ntÄ±lÄ± mod{Fore.RESET}")
    if failfast:
        test_params.append(f"{Fore.RED}hÄ±zlÄ± baÅŸarÄ±sÄ±zlÄ±k{Fore.RESET}")
    if test:
        test_params.append(f"{Fore.GREEN}belirli test: {test}{Fore.RESET}")
    if fix_warnings:
        test_params.append(f"{Fore.CYAN}uyarÄ±larÄ± gizle{Fore.RESET}")
    
    if test_params:
        logger.info(f"{Fore.BLUE}âš™ï¸  {Style.BRIGHT}Test parametreleri:{Style.RESET_ALL} {' | '.join(test_params)}")
    
    # Timeout ayarla - Mac'de SIGALRM iÃ§in Ã¶zel iÅŸlem
    if timeout > 0 and sys.platform != 'win32':
        signal.signal(signal.SIGALRM, handle_timeout)
        signal.alarm(timeout)
        logger.debug(f"Timeout {timeout} saniye olarak ayarlandÄ±")
    
    # Pytest argÃ¼manlarÄ±
    pytest_args = ['python', '-m', 'pytest']
    
    # Verbose mod
    if verbose:
        pytest_args.append('-v')
    
    # Failfast
    if failfast:
        pytest_args.append('-xvs')
    
    # UyarÄ± dÃ¼zeltmeleri
    if fix_warnings:
        pytest_args.append('--disable-warnings')
        print(f"{Fore.CYAN}âš™ï¸  UyarÄ±lar gizleniyor{Style.RESET_ALL}")
    
    # Belirli bir test
    if test:
        if not test.startswith('test_'):
            test = f'test_{test}'
        if not test.endswith('.py'):
            test = f'{test}.py'
        
        test_file = os.path.join(os.path.dirname(__file__), test)
        if os.path.exists(test_file):
            pytest_args.append(test_file)
        else:
            print(f"{Fore.RED}â›” HATA: Test dosyasÄ± bulunamadÄ±: {test_file}")
            return 1, {}
    
    # Asyncio mode strict
    pytest_args.append('--asyncio-mode=strict')
    
    # Testlerin baÅŸlangÄ±Ã§ zamanÄ±nÄ± kaydet
    start_time = time.time()
    
    # Test baÅŸladÄ± bilgisi
    logger.info(f"\n{Fore.CYAN}{Style.BRIGHT}â³ Testler Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor...{Style.RESET_ALL}")
    print(f"{Fore.BLUE}{'â”€' * 70}{Style.RESET_ALL}")
    
    result = 1  # VarsayÄ±lan olarak baÅŸarÄ±sÄ±z kabul et
    test_output = ""
    test_stats = {
        'total': 0,
        'passed': 0, 
        'failed': 0, 
        'skipped': 0, 
        'errors': 0,
        'xfailed': 0,
        'xpassed': 0,
        'warnings': 0
    }
    
    try:
        # Subprocess olarak pytest Ã§alÄ±ÅŸtÄ±rma
        process = subprocess.Popen(
            pytest_args,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            bufsize=1
        )
        
        # Ã‡Ä±ktÄ±yÄ± satÄ±r satÄ±r gerÃ§ek zamanlÄ± oku ve yazdÄ±r
        for line in process.stdout:
            sys.stdout.write(line)
            test_output += line
        
        # Ä°ÅŸlem tamamlandÄ±, Ã§Ä±kÄ±ÅŸ kodunu al
        process.stdout.close()
        result = process.wait()
        
        # Timeout'u iptal et
        if timeout > 0 and sys.platform != 'win32':
            signal.alarm(0)
        
        print(f"{Fore.BLUE}{'â”€' * 70}{Style.RESET_ALL}")
        
        # Test sonuÃ§larÄ±
        elapsed = time.time() - start_time
        
        # Test istatistiklerini Ã§Ä±karÄ±r
        test_stats = extract_test_results(test_output)
        
        # Sonucu gÃ¶ster - renkli ve emojili
        if result == 0 and test_stats['failed'] == 0 and test_stats['errors'] == 0:
            print(f"\n{Fore.GREEN}{Style.BRIGHT}âœ… TÃ¼m testler baÅŸarÄ±yla geÃ§ti!{Style.RESET_ALL}")
        else:
            print(f"\n{Fore.RED}{Style.BRIGHT}âŒ BazÄ± testler baÅŸarÄ±sÄ±z oldu!{Style.RESET_ALL}")
        
        # Test sÃ¼resini gÃ¶ster
        duration_color = Fore.GREEN if elapsed < 5 else Fore.YELLOW if elapsed < 15 else Fore.RED
        print(f"{Fore.BLUE}â±ï¸  Toplam sÃ¼re: {duration_color}{elapsed:.2f} saniye{Fore.RESET}")
        
        # DetaylÄ± test Ã¶zetini gÃ¶ster
        print_test_summary(test_stats, elapsed)
        
    except KeyboardInterrupt:
        print(f"\n{Fore.BLUE}{'â”€' * 70}{Style.RESET_ALL}")
        print(f"\n{Fore.YELLOW}{Style.BRIGHT}âš ï¸  Testler kullanÄ±cÄ± tarafÄ±ndan durduruldu.{Style.RESET_ALL}")
        
        # Ä°ÅŸlemi sonlandÄ±r
        if 'process' in locals() and process and process.poll() is None:
            process.terminate()
            try:
                process.wait(timeout=5)
            except subprocess.TimeoutExpired:
                process.kill()
        
        # Asenkron gÃ¶revleri temizlemeye Ã§alÄ±ÅŸ
        try:
            import asyncio
            loop = asyncio.get_event_loop()
            if not loop.is_closed():
                tasks = asyncio.all_tasks(loop)
                for task in tasks:
                    task.cancel()
                loop.run_until_complete(asyncio.gather(*tasks, return_exceptions=True))
                loop.close()
        except Exception:
            pass
        
        result = 1
    except Exception as e:
        print(f"\n{Fore.BLUE}{'â”€' * 70}{Style.RESET_ALL}")
        print(f"{Fore.RED}{Style.BRIGHT}â›” Testleri Ã§alÄ±ÅŸtÄ±rÄ±rken hata: {e}{Style.RESET_ALL}")
        result = 1
    finally:
        # Timeout'u iptal et
        if timeout > 0 and sys.platform != 'win32':
            signal.alarm(0)
    
    return result, test_stats

def test_extract_test_results_success():
    """
    Test istatistikleri Ã§Ä±karma - baÅŸarÄ± durumunda.
    
    Bu birim test fonksiyonu, extract_test_results fonksiyonunun
    baÅŸarÄ±lÄ± test sonuÃ§larÄ±nÄ± doÄŸru ÅŸekilde Ã§Ä±karabildiÄŸini doÄŸrular.
    """
    sample_output = """
    ============================= test session starts ==============================
    platform darwin -- Python 3.9.2, pytest-8.3.5, pluggy-1.5.0
    collected 10 items
    
    tests/test_example.py ..........                                      [100%]
    
    ========================= 10 passed in 0.12s =========================
    """
    stats = extract_test_results(sample_output)
    assert stats['total'] == 10
    assert stats['passed'] == 10
    assert stats['failed'] == 0

def test_extract_test_results_mixed():
    """
    Test istatistikleri Ã§Ä±karma - karÄ±ÅŸÄ±k sonuÃ§lar.
    
    Bu birim test fonksiyonu, extract_test_results fonksiyonunun
    karÄ±ÅŸÄ±k test sonuÃ§larÄ±nÄ± doÄŸru ÅŸekilde Ã§Ä±karabildiÄŸini doÄŸrular.
    """
    sample_output = """
    ============================= test session starts ==============================
    platform darwin -- Python 3.9.2, pytest-8.3.5, pluggy-1.5.0
    collected 10 items
    
    tests/test_example.py .....F..s.                                      [100%]
    
    ========================= 1 failed, 8 passed, 1 skipped, 2 warnings in 0.12s =========================
    """
    stats = extract_test_results(sample_output)
    assert stats['total'] == 10
    assert stats['passed'] == 8
    assert stats['failed'] == 1
    assert stats['skipped'] == 1
    assert stats['warnings'] == 2

def test_safe_logger_closed_handlers():
    """
    SafeLogger kapalÄ± handler'lara yazma denemesi.
    
    Bu birim test fonksiyonu, SafeLogger sÄ±nÄ±fÄ±nÄ±n handler'lar
    kapatÄ±ldÄ±ktan sonra log yazma giriÅŸimlerini engellediÄŸini doÄŸrular.
    """
    logger = SafeLogger("test_logger")
    handler = logging.StreamHandler(io.StringIO())
    logger.addHandler(handler)
    
    # Handler'larÄ± kapat
    logger.close_handlers()
    
    # KapalÄ± handler'lara yazma giriÅŸimi
    logger.info("Bu log yazÄ±lmamalÄ±")
    
    # Ã‡Ä±ktÄ± boÅŸ olmalÄ±
    assert handler.stream.getvalue() == ""

def test_subprocess_error_handling():
    """
    Subprocess hatalarÄ± ile baÅŸa Ã§Ä±kma.
    
    Bu birim test fonksiyonu, run_tests fonksiyonunun subprocess
    Ã§alÄ±ÅŸtÄ±rÄ±lmasÄ± sÄ±rasÄ±nda ortaya Ã§Ä±kan hatalarÄ± doÄŸru ÅŸekilde
    ele alabildiÄŸini doÄŸrular.
    """
    with patch('subprocess.Popen') as mock_popen:
        mock_popen.side_effect = OSError("Komut bulunamadÄ±")
        result, stats = run_tests(test="nonexistent")
        assert result != 0  # Hata kodu dÃ¶ndÃ¼rmeli

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Telegram Auto Message Bot Test Runner')
    parser.add_argument('-v', '--verbose', action='store_true', help='AyrÄ±ntÄ±lÄ± Ã§Ä±ktÄ± gÃ¶ster')
    parser.add_argument('-f', '--failfast', action='store_true', help='Ä°lk hatada dur')
    parser.add_argument('-t', '--test', help='Belirli bir test dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±r')
    parser.add_argument('--timeout', type=int, default=DEFAULT_TIMEOUT, 
                       help=f'Test zaman aÅŸÄ±mÄ± (saniye), 0 iÃ§in timeout yok (varsayÄ±lan: {DEFAULT_TIMEOUT})')
    parser.add_argument('--fix-warnings', action='store_true', help='pytest-asyncio uyarÄ±larÄ±nÄ± dÃ¼zelt')
    
    try:
        # Testleri Ã§alÄ±ÅŸtÄ±r
        args = parser.parse_args()
        exit_code, _ = run_tests(args.verbose, args.failfast, args.test, args.timeout, args.fix_warnings)
        
        # Program normal bir ÅŸekilde sonlanmadan Ã¶nce log handler'larÄ± kapat
        if isinstance(logger, SafeLogger):
            logger.close_handlers()
        
        sys.exit(exit_code)
    except Exception as e:
        print(f"{Fore.RED}{Style.BRIGHT}â›” Test betiÄŸinde beklenmeyen hata: {e}{Style.RESET_ALL}")
        
        # Herhangi bir hata durumunda da log handler'larÄ± kapat
        if isinstance(logger, SafeLogger):
            logger.close_handlers()
        
        sys.exit(1)